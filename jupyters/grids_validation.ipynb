{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = os.getenv('HYPERNET_DATA_DIR', os.path.join('..', '..', 'hypernet-data'))\n",
    "RESULTS_DIR = os.path.join(os.getenv('HYPERNET_RESULTS_DIR', os.path.join('..', '..', 'hypernet-data', 'results')), 'grids_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from utils import load_patches, combine_patches\n",
    "from python_research.experiments.utils.datasets.hyperspectral_dataset import HyperspectralDataset\n",
    "from python_research.experiments.utils.datasets.subset import BalancedSubset\n",
    "from python_research.experiments.multiple_feature_learning.builders.keras_builders import build_3d_model, build_settings_for_dataset, build_1d_model\n",
    "from python_research.preprocessing.grids.grid_extraction import extract_grids\n",
    "%matplotlib inline\n",
    "\n",
    "PATCHES_DIRECTORY = \"\"\n",
    "DATASET_PATH = os.path.join(DATA_DIR, 'PaviaU_corrected.npy')\n",
    "DATASET_GT_PATH = os.path.join(DATA_DIR, 'PaviaU_gt.npy')\n",
    "OUTPUT_PATH = RESULTS_DIR\n",
    "PATCH_SIZE = (17, 30)\n",
    "PIXEL_neighborhood = 1\n",
    "TOTAL_NUMBER_OF_TRAIN_SAMPLES = 2700\n",
    "CLASSES_COUNT = 9\n",
    "PATIENCE = 15\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "os.makedirs(\"grids_validation\", exist_ok=True)\n",
    "\n",
    "\n",
    "# Load data if path to the folder with patches is specified\n",
    "if PATCHES_DIRECTORY != \"\":\n",
    "    train_data, test_data = load_patches(PATCHES_DIRECTORY, PIXEL_neighborhood)\n",
    "    dataset_image = test_data.x[:, :, randint(0, test_data.x.shape[-1])]\n",
    "    train_data.normalize_labels()\n",
    "    test_data.normalize_labels()\n",
    "    bands_count = test_data.shape[-1]\n",
    "    if PIXEL_neighborhood == 1:\n",
    "        train_data.expand_dims(axis=-1)\n",
    "        test_data.expand_dims(axis=-1)\n",
    "    val_data = BalancedSubset(train_data, 0.1)\n",
    "# Extract grids from provided dataset if path was not specified\n",
    "else:\n",
    "    patches, test_set, dataset_image = extract_grids(DATASET_PATH, DATASET_GT_PATH, PATCH_SIZE, \n",
    "                                                     TOTAL_NUMBER_OF_TRAIN_SAMPLES)\n",
    "    train_data, test_data = combine_patches(patches[0], patches[1], test_set[0], test_set[1], \n",
    "                                            PIXEL_neighborhood)\n",
    "    train_data.normalize_labels()\n",
    "    test_data.normalize_labels()\n",
    "    if PIXEL_neighborhood == 1:\n",
    "        train_data.expand_dims(axis=-1)\n",
    "        test_data.expand_dims(axis=-1)\n",
    "    val_data = BalancedSubset(train_data, 0.1)\n",
    "# Show location of extracted grids\n",
    "plt.imshow(dataset_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize data\n",
    "max_ = train_data.max if train_data.max > val_data.max else val_data.max\n",
    "min_ = train_data.min if train_data.min < val_data.min else val_data.min\n",
    "train_data.normalize_min_max(min_=min_, max_=max_)\n",
    "val_data.normalize_min_max(min_=min_, max_=max_)\n",
    "test_data.normalize_min_max(min_=min_, max_=max_)\n",
    "\n",
    "# Build model\n",
    "if PIXEL_neighborhood == 1:\n",
    "    model = build_1d_model((test_data.shape[1:]), 200, 5, CLASSES_COUNT)\n",
    "else:\n",
    "    settings = build_settings_for_dataset((PIXEL_neighborhood,\n",
    "                                           PIXEL_neighborhood))\n",
    "    model = build_3d_model(settings, CLASSES_COUNT, test_data.shape[-1])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early = EarlyStopping(patience=PATIENCE)\n",
    "checkpoint = ModelCheckpoint(OUTPUT_PATH + \"_model\", save_best_only=True)\n",
    "\n",
    "model.fit(x=train_data.get_data(), y=train_data.get_one_hot_labels(CLASSES_COUNT), batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=False,\n",
    "          callbacks=[early, checkpoint], validation_data=[val_data.get_data(), val_data.get_one_hot_labels(CLASSES_COUNT)])\n",
    "\n",
    "best_model = load_model(OUTPUT_PATH + \"_model\")\n",
    "\n",
    "# Evaluate test set score\n",
    "accuracy = best_model.evaluate(x=test_data.get_data(), y=test_data.get_one_hot_labels(CLASSES_COUNT))[1]\n",
    "print(\"Test set accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
