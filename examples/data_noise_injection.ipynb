{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitdecentconda195be60078e74141843b635847adeecd",
   "display_name": "Python 3.6.10 64-bit ('decent': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Noise injection into data\n",
    "\n",
    "This example presents how the the noise can be injected into any part of the dataset: train, test and validation.\n",
    "There are three types of noise implemented: \n",
    "- Gaussian\n",
    "- Impulsive\n",
    "- Shot\n",
    "\n",
    "There are a few parameters which indicate how a given noise behaves:\n",
    "- *pa* - Fraction of noisy pixels, the number of affected samples is calculated by: floor(n_samples * pa).\n",
    "- *pb* - Fraction of noisy bands. When established the number of samples that undergo noise injection, for each sample the: floor(n_bands * pb) bands are affected.\n",
    "- *bc* - Boolean indicating whether the indexes of affected bands, are constant for each sample. When set to: False, different bands can be augmented with noise for each pixel.\n",
    "- *mean* - Gaussian noise parameter, the mean of the normal distribution.\n",
    "- *std* - Gaussian noise parameter, standard deviation of the normal distribution.\n",
    "- *pw* - Impulsive noise parameter, ratio of whitened pixels for the affected set of samples.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/michal/anaconda3/envs/decent/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import clize\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "from clize.parameters import multi\n",
    "\n",
    "from scripts import evaluate_model, prepare_data, artifacts_reporter, train_model\n",
    "from ml_intuition.enums import Splits, Experiment\n",
    "from ml_intuition.data.io import load_processed_h5\n",
    "from ml_intuition.data.utils import get_mlflow_artifacts_path, parse_train_size\n",
    "from ml_intuition.data.loggers import log_params_to_mlflow, log_tags_to_mlflow"
   ]
  },
  {
   "source": [
    "Specify path to the `.npy` dataset and ground truth, as well as the output path to store all the artifacts."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_PATH = 'data_noise_injection_results'\n",
    "DATA_FILE_PATH = os.path.join(os.path.dirname(os.getcwd()), 'datasets/pavia/pavia.npy')\n",
    "GT_FILE_PAT = os.path.join(os.path.dirname(os.getcwd()), 'datasets/pavia/pavia_gt.npy')\n",
    "experiment_dest_path = os.path.join(DEST_PATH, 'experiment_0')\n",
    "os.makedirs(experiment_dest_path, exist_ok=True)"
   ]
  },
  {
   "source": [
    "# Prepare the data\n",
    "\n",
    "To fit into the the pipeline, the data has to be preprocessed. It is achieved by the `prepare_data.main` function. It accepts a path to a `.npy` file with the original cube as well as the corresponding ground truth.  In this example, we randomly extract 250 samples from each class (balanced scenario), use 10% of them as validation set, and extract only spectral information of a pixel. The returned object is a dictiornary with three keys: `train`, `test` and `val`. Each of them contains an additional dictionary with `data` and `labels` keys, holding corresponding `numpy.ndarray` objects with the data. For more details about the parameters, refer to the documentation of `prepare_data.main` function (located in `scripts/prepare_data`)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.main(data_file_path=DATA_FILE_PATH,\n",
    "                            ground_truth_path=GT_FILE_PAT,\n",
    "                            output_path=None,\n",
    "                            train_size=250,\n",
    "                            val_size=0.1,\n",
    "                            stratified=True,\n",
    "                            background_label=0,\n",
    "                            channels_idx=2,\n",
    "                            neighborhood_size=None,\n",
    "                            save_data=False,\n",
    "                            seed=0)"
   ]
  },
  {
   "source": [
    "# Train the model with nosiy training set\n",
    "\n",
    "The function `trian_model.train` executed the trainig procedure. In order to inject noise into the training set, provide `noise` with a name of the noise type, `noise_sets` with the set you would like to augment, and `noise_params` with the noise parameters. Trained model will be stored under `experiment_dest_path` folder path."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_model.train(model_name='model_2d',\n",
    "                    kernel_size=5,\n",
    "                    n_kernels=200,\n",
    "                    n_layers=1,\n",
    "                    dest_path=experiment_dest_path,\n",
    "                    data=data,\n",
    "                    sample_size=103,\n",
    "                    n_classes=9,\n",
    "                    lr=0.001,\n",
    "                    batch_size=128,\n",
    "                    epochs=200,\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    patience=15,\n",
    "                    noise=['gaussian'],\n",
    "                    noise_sets=['train'],\n",
    "                    noise_params=\"{\\\"mean\\\": 0, \\\"std\\\": 1, \\\"pa\\\": 0.1, \\\"pb\\\": 1}\")\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 99, 1, 200)        1200      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 1, 200)         200200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 828,889\n",
      "Trainable params: 828,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2025 samples, validate on 225 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.8766 - acc: 0.2884 - val_loss: 1.2753 - val_acc: 0.5244\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.3402 - acc: 0.5190 - val_loss: 1.1099 - val_acc: 0.6622\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1.0450 - acc: 0.5891 - val_loss: 0.8017 - val_acc: 0.6533\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.8930 - acc: 0.6123 - val_loss: 0.7553 - val_acc: 0.6800\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.7653 - acc: 0.6825 - val_loss: 0.6508 - val_acc: 0.7067\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.7342 - acc: 0.6775 - val_loss: 0.6775 - val_acc: 0.7067\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6815 - acc: 0.7047 - val_loss: 0.5488 - val_acc: 0.7467\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.5820 - acc: 0.7412 - val_loss: 0.5743 - val_acc: 0.7422\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.5682 - acc: 0.7467 - val_loss: 0.5409 - val_acc: 0.7778\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.5695 - acc: 0.7684 - val_loss: 0.5560 - val_acc: 0.7556\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.5140 - acc: 0.7758 - val_loss: 0.5169 - val_acc: 0.7822\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.4595 - acc: 0.7990 - val_loss: 0.4999 - val_acc: 0.7867\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.4514 - acc: 0.8064 - val_loss: 0.5166 - val_acc: 0.7511\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.4170 - acc: 0.8212 - val_loss: 0.4742 - val_acc: 0.7911\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.3994 - acc: 0.8128 - val_loss: 0.4687 - val_acc: 0.7644\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.3958 - acc: 0.8311 - val_loss: 0.5154 - val_acc: 0.7956\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.3613 - acc: 0.8365 - val_loss: 0.4639 - val_acc: 0.8000\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.3652 - acc: 0.8415 - val_loss: 0.4501 - val_acc: 0.7867\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.3535 - acc: 0.8444 - val_loss: 0.4074 - val_acc: 0.7822\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.3435 - acc: 0.8375 - val_loss: 0.4991 - val_acc: 0.7600\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.3967 - acc: 0.8380 - val_loss: 0.4346 - val_acc: 0.7956\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.3657 - acc: 0.8459 - val_loss: 0.4492 - val_acc: 0.7778\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.3302 - acc: 0.8533 - val_loss: 0.5275 - val_acc: 0.8178\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.3635 - acc: 0.8435 - val_loss: 0.4759 - val_acc: 0.7822\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.3305 - acc: 0.8637 - val_loss: 0.3988 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.3109 - acc: 0.8652 - val_loss: 0.3968 - val_acc: 0.8311\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.3108 - acc: 0.8632 - val_loss: 0.4034 - val_acc: 0.8267\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.3090 - acc: 0.8652 - val_loss: 0.5144 - val_acc: 0.7733\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.3275 - acc: 0.8523 - val_loss: 0.3608 - val_acc: 0.8356\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.3059 - acc: 0.8711 - val_loss: 0.3661 - val_acc: 0.8222\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.2482 - acc: 0.8899 - val_loss: 0.3589 - val_acc: 0.8356\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.2466 - acc: 0.8963 - val_loss: 0.3765 - val_acc: 0.8667\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.2474 - acc: 0.8948 - val_loss: 0.3425 - val_acc: 0.8356\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.2669 - acc: 0.8859 - val_loss: 0.4009 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2366 - acc: 0.9017 - val_loss: 0.3029 - val_acc: 0.8489\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.2381 - acc: 0.8993 - val_loss: 0.3325 - val_acc: 0.8533\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.2243 - acc: 0.9042 - val_loss: 0.3578 - val_acc: 0.8489\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.2476 - acc: 0.8963 - val_loss: 0.3516 - val_acc: 0.8756\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.2286 - acc: 0.9062 - val_loss: 0.3470 - val_acc: 0.8533\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.2872 - acc: 0.8785 - val_loss: 0.3036 - val_acc: 0.8622\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.2898 - acc: 0.8835 - val_loss: 0.3757 - val_acc: 0.8311\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.2736 - acc: 0.8909 - val_loss: 0.3445 - val_acc: 0.8311\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.2772 - acc: 0.8889 - val_loss: 0.3393 - val_acc: 0.8533\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.2701 - acc: 0.8919 - val_loss: 0.3880 - val_acc: 0.8356\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.2474 - acc: 0.9062 - val_loss: 0.3104 - val_acc: 0.8844\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.2401 - acc: 0.8963 - val_loss: 0.3277 - val_acc: 0.8667\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.2310 - acc: 0.9072 - val_loss: 0.3448 - val_acc: 0.8444\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.2166 - acc: 0.9096 - val_loss: 0.3015 - val_acc: 0.8622\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.2450 - acc: 0.8978 - val_loss: 0.3115 - val_acc: 0.8667\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.2152 - acc: 0.9121 - val_loss: 0.3081 - val_acc: 0.8756\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.2203 - acc: 0.9052 - val_loss: 0.3671 - val_acc: 0.8400\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.2086 - acc: 0.9151 - val_loss: 0.2805 - val_acc: 0.8756\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.1924 - acc: 0.9225 - val_loss: 0.3424 - val_acc: 0.8622\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.1835 - acc: 0.9244 - val_loss: 0.2751 - val_acc: 0.8711\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.1888 - acc: 0.9264 - val_loss: 0.2981 - val_acc: 0.8711\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.2002 - acc: 0.9225 - val_loss: 0.2876 - val_acc: 0.8622\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.1968 - acc: 0.9240 - val_loss: 0.2659 - val_acc: 0.8756\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.1802 - acc: 0.9269 - val_loss: 0.2727 - val_acc: 0.8667\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.2065 - acc: 0.9160 - val_loss: 0.5268 - val_acc: 0.7956\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.2355 - acc: 0.9032 - val_loss: 0.3214 - val_acc: 0.8711\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.1940 - acc: 0.9230 - val_loss: 0.2883 - val_acc: 0.8711\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.1789 - acc: 0.9230 - val_loss: 0.3159 - val_acc: 0.8444\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.1747 - acc: 0.9323 - val_loss: 0.2645 - val_acc: 0.9067\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.1837 - acc: 0.9230 - val_loss: 0.3250 - val_acc: 0.8711\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.2013 - acc: 0.9195 - val_loss: 0.2648 - val_acc: 0.8844\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.1605 - acc: 0.9348 - val_loss: 0.2758 - val_acc: 0.8800\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.1815 - acc: 0.9230 - val_loss: 0.3025 - val_acc: 0.9111\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.1831 - acc: 0.9225 - val_loss: 0.3180 - val_acc: 0.8667\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.1743 - acc: 0.9294 - val_loss: 0.2651 - val_acc: 0.8578\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.1685 - acc: 0.9323 - val_loss: 0.2774 - val_acc: 0.8889\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.1724 - acc: 0.9338 - val_loss: 0.3262 - val_acc: 0.8578\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.2018 - acc: 0.9170 - val_loss: 0.2786 - val_acc: 0.8800\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.1866 - acc: 0.9249 - val_loss: 0.3146 - val_acc: 0.8667\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.1817 - acc: 0.9210 - val_loss: 0.2495 - val_acc: 0.8844\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.1574 - acc: 0.9353 - val_loss: 0.2809 - val_acc: 0.8667\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.1631 - acc: 0.9333 - val_loss: 0.2452 - val_acc: 0.8711\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.1531 - acc: 0.9407 - val_loss: 0.2786 - val_acc: 0.8933\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.1845 - acc: 0.9225 - val_loss: 0.2886 - val_acc: 0.8800\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.1775 - acc: 0.9274 - val_loss: 0.2971 - val_acc: 0.8800\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.1942 - acc: 0.9180 - val_loss: 0.2346 - val_acc: 0.8978\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.1918 - acc: 0.9215 - val_loss: 0.2896 - val_acc: 0.8844\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.1648 - acc: 0.9368 - val_loss: 0.2516 - val_acc: 0.8889\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.1490 - acc: 0.9481 - val_loss: 0.2231 - val_acc: 0.9111\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.1394 - acc: 0.9477 - val_loss: 0.2799 - val_acc: 0.8756\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.1623 - acc: 0.9388 - val_loss: 0.3106 - val_acc: 0.8800\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.1740 - acc: 0.9328 - val_loss: 0.2728 - val_acc: 0.8756\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.1869 - acc: 0.9200 - val_loss: 0.3492 - val_acc: 0.8756\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.1741 - acc: 0.9269 - val_loss: 0.2728 - val_acc: 0.8844\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.1428 - acc: 0.9407 - val_loss: 0.2019 - val_acc: 0.9022\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.1420 - acc: 0.9447 - val_loss: 0.2493 - val_acc: 0.8889\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.1425 - acc: 0.9452 - val_loss: 0.2225 - val_acc: 0.8933\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.1373 - acc: 0.9432 - val_loss: 0.2473 - val_acc: 0.8844\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.1442 - acc: 0.9442 - val_loss: 0.2443 - val_acc: 0.8800\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.1377 - acc: 0.9452 - val_loss: 0.2667 - val_acc: 0.8889\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.1569 - acc: 0.9412 - val_loss: 0.2817 - val_acc: 0.8800\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.2041 - acc: 0.9220 - val_loss: 0.2803 - val_acc: 0.8800\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.1886 - acc: 0.9274 - val_loss: 0.2485 - val_acc: 0.8978\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.1981 - acc: 0.9225 - val_loss: 0.2442 - val_acc: 0.9156\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.2350 - acc: 0.9244 - val_loss: 0.2126 - val_acc: 0.9200\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.2257 - acc: 0.9279 - val_loss: 0.2794 - val_acc: 0.8800\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.3085 - acc: 0.8998 - val_loss: 0.2617 - val_acc: 0.8933\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.2221 - acc: 0.9121 - val_loss: 0.2589 - val_acc: 0.8978\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.1993 - acc: 0.9175 - val_loss: 0.2283 - val_acc: 0.8978\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.1803 - acc: 0.9264 - val_loss: 0.2823 - val_acc: 0.8622\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Evaluate the model\n",
    "\n",
    "Evaluate the model, calculating all metrics. All arfticats will be stored under provided `experiment_dest_path`. In this step, it is also possible to inject nosie into the `test` set, similarly to the previous function call."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/michal/anaconda3/envs/decent/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py:542: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n  append_fn(tensor_proto, proto_values)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model.evaluate(\n",
    "    model_path=os.path.join(experiment_dest_path, 'model_2d'),\n",
    "    data=data,\n",
    "    dest_path=experiment_dest_path,\n",
    "    n_classes=9,\n",
    "    batch_size=1024,\n",
    "    noise=['gaussian'],\n",
    "    noise_sets=['test'],\n",
    "    noise_params=\"{\\\"mean\\\": 0, \\\"std\\\": 1, \\\"pa\\\": 0.1, \\\"pb\\\": 1}\")\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}