{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters description for the unmixing experiments\n",
    "Train and evaluate the convolutional neural network (CNN)\n",
    "as well as the deep convolutional autoencoder (DCAE)\n",
    "for the unmixing problem. <br>\n",
    "Exemplary hyperparameters to set:<br>\n",
    "- --data-file-path - path to the hyperspectral image (HSI).\n",
    "- --ground-truth-path - path to the ground truth map containing\n",
    "the fractions of abundances for entire HSI.\n",
    "- --train-size - magnitude of the learning set that is utilized\n",
    "to fine-tune the weights of the model.\n",
    "- --sub-test-size - size of the test set to evaluate\n",
    "the generalization of the model. It is sampled from the remaining\n",
    "HSI excluding the training subset. If not specified, all non-training samples\n",
    "constitute the test set.<br>Can be employed in the case of experiments\n",
    "when changing the magnitudes of training sets while keeping the size of testing\n",
    "sets constant.\n",
    "- --val-size - fraction or size of the validation subset, it is designed to\n",
    "monitor the overfitting.\n",
    "- --channels-idx - index of the spectral dimension in input HSI.\n",
    "- batch-size - number of samples per update step in the training phase.\n",
    "- --shuffle - indicates whether to shuffle the dataset in experiment.\n",
    "- --patience - stopping condition for a specific number of epochs without\n",
    "improvement.\n",
    "- --model-name - name of the utilized model, exemplary values:<br>\n",
    "unmixing_pixel_based_cnn, unmixing_cube_based_cnn, unmixing_pixel_based_dcae,\n",
    "unmixing_cube_based_dcae for the pixel-based, cube-based CNN and DCAE\n",
    "respectively.\n",
    "- --sample-size - number of spectral bands in a given HSI.\n",
    "- --neighborhood-size - size of the spatial extent which is employed for each\n",
    "sample in the form of local neighboring pixels. Most cases allows to leverage\n",
    "the quality of the segmentation as well as the unmixing.\n",
    "- --n-classes - number of endmembers in the HSI for which the abundances\n",
    "will be estimated by the model.\n",
    "- --lr - learning rate, regulates the step size during weights updates.\n",
    "- --epochs - second stopping condition, i.e., the maximum number of epochs.\n",
    "- --verbose - verbosity mode.\n",
    "- --save-data - indicates whether to save the training and test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cube-based DCAE\n",
    "We specify the necessary parameters for the experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Execute cube-based DCAE:\n",
    "from os.path import join\n",
    "\n",
    "base_path = r'../datasets/urban'\n",
    "data_file_path = join(base_path, 'urban.npy')\n",
    "ground_truth_path = join(base_path, 'urban_gt.npy')\n",
    "endmembers_path = join(base_path, 'urban_m.npy')\n",
    "train_size = 15500\n",
    "sub_test_size = 47249\n",
    "val_size = 0.1\n",
    "channels_idx = -1\n",
    "batch_size = 256\n",
    "shuffle = True\n",
    "patience = 3\n",
    "model_name = 'unmixing_cube_based_dcae'\n",
    "sample_size = 162\n",
    "neighborhood_size = 5\n",
    "n_classes = 6\n",
    "dest_path = join('../examples', 'unmixing_results')\n",
    "lr = 0.0005\n",
    "epochs = 10\n",
    "verbose = 2\n",
    "save_data = False\n",
    "use_mlflow = False\n",
    "seed = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ml_intuition import enums\n",
    "from ml_intuition.data.utils import parse_train_size, subsample_test_set\n",
    "from scripts import prepare_data\n",
    "from scripts.unmixing import train_unmixing, evaluate_unmixing\n",
    "\n",
    "dcae_dest_path = join(dest_path, 'cube-based-dcae')\n",
    "os.makedirs(dcae_dest_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare data\n",
    "We prepare data for the unmixing by utilizing the *prepare_data.main* method.\n",
    "It accepts various parameters such as path to the data file or ground-truth\n",
    "for a specific HSI. Furthermore, magnitude of the learning set can be also specified.\n",
    "Moreover, the method accepts the neighborhood size parameter, which specifies the\n",
    "spatial extent of ech sample. For each run in the experiment for the\n",
    "sake of reproducibility, it is possible to set a specific seed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Prepare data for unmixing:\n",
    "data = prepare_data.main(data_file_path=data_file_path,\n",
    "                         ground_truth_path=ground_truth_path,\n",
    "                         train_size=parse_train_size(train_size),\n",
    "                         val_size=val_size,\n",
    "                         stratified=False,\n",
    "                         background_label=-1,\n",
    "                         channels_idx=channels_idx,\n",
    "                         neighborhood_size=neighborhood_size,\n",
    "                         save_data=save_data,\n",
    "                         seed=seed,\n",
    "                         use_unmixing=True)\n",
    "# Subsample the test set to constitute a constant size:\n",
    "if sub_test_size is not None:\n",
    "    subsample_test_set(data[enums.Dataset.TEST], sub_test_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and evaluate the model\n",
    "Few parameters previously initialized are employed in this step, e.g.,\n",
    "the name of the model, size of the spectral extent,\n",
    "learning rate and batch size.\n",
    "The results including the metrics are stored in *dcae_dest_path* directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\Å‚ukasz\\desktop\\machine-learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:125: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  tensor_proto.float_val.extend([np.asscalar(x) for x in proto_values])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 3, 3, 160, 16)     448       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 158, 32)     13856     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 156, 64)     6208      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 154, 128)    24704     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19712)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5046528   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 162)               1134      \n",
      "=================================================================\n",
      "Total params: 5,094,420\n",
      "Trainable params: 5,093,286\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/10\n",
      " - 20s - loss: 27.2249 - spectral_information_divergence_loss: 27.2249 - val_loss: 14.2872 - val_spectral_information_divergence_loss: 14.2872\n",
      "Epoch 2/10\n",
      " - 20s - loss: 13.3596 - spectral_information_divergence_loss: 13.3596 - val_loss: 13.2390 - val_spectral_information_divergence_loss: 13.2390\n",
      "Epoch 3/10\n",
      " - 21s - loss: 12.6607 - spectral_information_divergence_loss: 12.6607 - val_loss: 12.9163 - val_spectral_information_divergence_loss: 12.9163\n",
      "Epoch 4/10\n",
      " - 22s - loss: 12.2737 - spectral_information_divergence_loss: 12.2737 - val_loss: 12.6324 - val_spectral_information_divergence_loss: 12.6324\n",
      "Epoch 5/10\n",
      " - 21s - loss: 11.9842 - spectral_information_divergence_loss: 11.9842 - val_loss: 12.4379 - val_spectral_information_divergence_loss: 12.4379\n",
      "Epoch 6/10\n",
      " - 21s - loss: 11.8302 - spectral_information_divergence_loss: 11.8302 - val_loss: 12.4098 - val_spectral_information_divergence_loss: 12.4098\n",
      "Epoch 7/10\n",
      " - 21s - loss: 11.7662 - spectral_information_divergence_loss: 11.7662 - val_loss: 12.3474 - val_spectral_information_divergence_loss: 12.3474\n",
      "Epoch 8/10\n",
      " - 21s - loss: 11.7180 - spectral_information_divergence_loss: 11.7180 - val_loss: 12.3371 - val_spectral_information_divergence_loss: 12.3371\n",
      "Epoch 9/10\n",
      " - 21s - loss: 11.6882 - spectral_information_divergence_loss: 11.6882 - val_loss: 12.3316 - val_spectral_information_divergence_loss: 12.3316\n",
      "Epoch 10/10\n",
      " - 22s - loss: 11.6267 - spectral_information_divergence_loss: 11.6267 - val_loss: 12.2947 - val_spectral_information_divergence_loss: 12.2947\n",
      "(47249, 6)\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "train_unmixing.train(model_name=model_name,\n",
    "                     dest_path=dcae_dest_path,\n",
    "                     data=data,\n",
    "                     sample_size=sample_size,\n",
    "                     neighborhood_size=neighborhood_size,\n",
    "                     n_classes=n_classes,\n",
    "                     lr=lr,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=verbose,\n",
    "                     shuffle=shuffle,\n",
    "                     patience=patience,\n",
    "                     endmembers_path=endmembers_path,\n",
    "                     seed=seed)\n",
    "# Evaluate the model:\n",
    "evaluate_unmixing.evaluate(\n",
    "    model_path=os.path.join(dcae_dest_path, model_name),\n",
    "    data=data,\n",
    "    dest_path=dcae_dest_path,\n",
    "    neighborhood_size=neighborhood_size,\n",
    "    batch_size=batch_size,\n",
    "    endmembers_path=endmembers_path)\n",
    "tf.keras.backend.clear_session()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pixel-based CNN\n",
    "We perform the same steps for the pixel-based CNN model, however a few parameters\n",
    "must be altered. Since we utilize only the spectral dimension, the\n",
    "*neighborhood_size* is set to *None*, the learning rate is also adjusted.\n",
    "The *endmembers_path* is also not needed anymore, since we train the\n",
    "model on the fractions of abundances of each endmember."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 1, 1, 158, 3)      18        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 1, 1, 79, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 76, 6)       78        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 1, 1, 38, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 34, 12)      372       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 17, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 14, 24)      1176      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 1, 7, 24)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 192)               32448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               28950     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 906       \n",
      "=================================================================\n",
      "Total params: 63,948\n",
      "Trainable params: 63,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.0219 - cnn_rmse: 0.1350 - overall_rms_abundance_angle_distance: 0.4606 - sum_per_class_rmse: 0.7875 - val_loss: 0.0056 - val_cnn_rmse: 0.0744 - val_overall_rms_abundance_angle_distance: 0.2624 - val_sum_per_class_rmse: 0.4397\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.0052 - cnn_rmse: 0.0721 - overall_rms_abundance_angle_distance: 0.2530 - sum_per_class_rmse: 0.4260 - val_loss: 0.0036 - val_cnn_rmse: 0.0597 - val_overall_rms_abundance_angle_distance: 0.2016 - val_sum_per_class_rmse: 0.3556\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.0030 - cnn_rmse: 0.0541 - overall_rms_abundance_angle_distance: 0.1853 - sum_per_class_rmse: 0.3197 - val_loss: 0.0025 - val_cnn_rmse: 0.0497 - val_overall_rms_abundance_angle_distance: 0.1655 - val_sum_per_class_rmse: 0.2916\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0024 - cnn_rmse: 0.0490 - overall_rms_abundance_angle_distance: 0.1645 - sum_per_class_rmse: 0.2884 - val_loss: 0.0020 - val_cnn_rmse: 0.0443 - val_overall_rms_abundance_angle_distance: 0.1520 - val_sum_per_class_rmse: 0.2624\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0022 - cnn_rmse: 0.0468 - overall_rms_abundance_angle_distance: 0.1568 - sum_per_class_rmse: 0.2753 - val_loss: 0.0018 - val_cnn_rmse: 0.0420 - val_overall_rms_abundance_angle_distance: 0.1410 - val_sum_per_class_rmse: 0.2487\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0019 - cnn_rmse: 0.0432 - overall_rms_abundance_angle_distance: 0.1450 - sum_per_class_rmse: 0.2540 - val_loss: 0.0014 - val_cnn_rmse: 0.0377 - val_overall_rms_abundance_angle_distance: 0.1286 - val_sum_per_class_rmse: 0.2228\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0016 - cnn_rmse: 0.0402 - overall_rms_abundance_angle_distance: 0.1353 - sum_per_class_rmse: 0.2360 - val_loss: 0.0016 - val_cnn_rmse: 0.0396 - val_overall_rms_abundance_angle_distance: 0.1324 - val_sum_per_class_rmse: 0.2347\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0013 - cnn_rmse: 0.0360 - overall_rms_abundance_angle_distance: 0.1221 - sum_per_class_rmse: 0.2117 - val_loss: 0.0014 - val_cnn_rmse: 0.0379 - val_overall_rms_abundance_angle_distance: 0.1283 - val_sum_per_class_rmse: 0.2235\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0012 - cnn_rmse: 0.0347 - overall_rms_abundance_angle_distance: 0.1181 - sum_per_class_rmse: 0.2037 - val_loss: 0.0011 - val_cnn_rmse: 0.0329 - val_overall_rms_abundance_angle_distance: 0.1099 - val_sum_per_class_rmse: 0.1927\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0010 - cnn_rmse: 0.0321 - overall_rms_abundance_angle_distance: 0.1099 - sum_per_class_rmse: 0.1883 - val_loss: 0.0012 - val_cnn_rmse: 0.0339 - val_overall_rms_abundance_angle_distance: 0.1146 - val_sum_per_class_rmse: 0.1999\n",
      "(47249, 6)\n"
     ]
    }
   ],
   "source": [
    "# Execute the pixel-based CNN:\n",
    "endmembers_path = None\n",
    "model_name = 'unmixing_pixel_based_cnn'\n",
    "lr = 0.01\n",
    "neighborhood_size = None\n",
    "cnn_dest_path = join(dest_path, 'pixel-based-cnn')\n",
    "os.makedirs(cnn_dest_path, exist_ok=True)\n",
    "\n",
    "# Prepare data for unmixing:\n",
    "data = prepare_data.main(data_file_path=data_file_path,\n",
    "                         ground_truth_path=ground_truth_path,\n",
    "                         train_size=parse_train_size(train_size),\n",
    "                         val_size=val_size,\n",
    "                         stratified=False,\n",
    "                         background_label=-1,\n",
    "                         channels_idx=channels_idx,\n",
    "                         neighborhood_size=neighborhood_size,\n",
    "                         save_data=save_data,\n",
    "                         seed=seed,\n",
    "                         use_unmixing=True)\n",
    "# Subsample the test set to constitute a constant size:\n",
    "if sub_test_size is not None:\n",
    "    subsample_test_set(data[enums.Dataset.TEST], sub_test_size)\n",
    "# Train the model:\n",
    "train_unmixing.train(model_name=model_name,\n",
    "                     dest_path=cnn_dest_path,\n",
    "                     data=data,\n",
    "                     sample_size=sample_size,\n",
    "                     neighborhood_size=neighborhood_size,\n",
    "                     n_classes=n_classes,\n",
    "                     lr=lr,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=verbose,\n",
    "                     shuffle=shuffle,\n",
    "                     patience=patience,\n",
    "                     endmembers_path=endmembers_path,\n",
    "                     seed=seed)\n",
    "# Evaluate the model:\n",
    "evaluate_unmixing.evaluate(\n",
    "    model_path=os.path.join(cnn_dest_path, model_name),\n",
    "    data=data,\n",
    "    dest_path=cnn_dest_path,\n",
    "    neighborhood_size=neighborhood_size,\n",
    "    batch_size=batch_size,\n",
    "    endmembers_path=endmembers_path)\n",
    "tf.keras.backend.clear_session()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}