{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Train and evaluate the convolutional neural network (CNN)\n",
    "as well as the deep convolutional autoencoder (DCAE)\n",
    "for the unmixing problem. <br>\n",
    "Exemplary hyperparameters to set:<br>\n",
    "- --data-file-path - path to the hyperspectral image (HSI).\n",
    "- --ground-truth-path - path to the ground truth map containing\n",
    "the fractions of abundances for entire HSI.\n",
    "- --train-size - magnitude of the learning set that is utilized\n",
    "to fine-tune the weights of the model.\n",
    "- --sub-test-size - size of the test set to evaluate\n",
    "the generalization of the model. It is sampled from the remaining\n",
    "HSI excluding the training subset. If not specified, all non-training samples\n",
    "constitute the test set.<br>Can be employed in the case of experiments\n",
    "when changing the magnitudes of training sets but keeping the size of test\n",
    "set constant.\n",
    "- --val-size - fraction or size of the validation subset, it is designed to\n",
    "monitor the overfitting.\n",
    "- --channels-idx - index of the spectral dimension in input HSI.\n",
    "- batch-size - number of samples per update step in the training phase.\n",
    "- --shuffle - indicates whether to shuffle the dataset in experiment.\n",
    "- --patience - stopping condition for a specific number of epochs without\n",
    "improvement.\n",
    "- --model-name - name of the utilized model, exemplary values:<br>\n",
    "unmixing_pixel_based_cnn, unmixing_cube_based_cnn, unmixing_pixel_based_dcae,\n",
    "unmixing_cube_based_dcae for the pixel-based, cube-based CNN and DCAE\n",
    "respectively.\n",
    "- --sample-size - number of spectral bands in a given HSI.\n",
    "- --neighborhood-size - size of the spatial extent which is employed for each\n",
    "sample in the form of local neighboring pixels. Most cases allows to leverage\n",
    "the quality of the segmentation as well as the unmixing.\n",
    "- --n-classes - number of endmembers in the HSI for which the abundances\n",
    "will be estimated by the model.\n",
    "- --lr - learning rate, regulates the step size during weights updates.\n",
    "- --epochs - second stopping condition, i.e., the maximum number of epochs.\n",
    "- --verbose - verbosity mode.\n",
    "- --n-runs - number of repetitions of each experiment,\n",
    "each one has its own seed for the sake of reproducibility.\n",
    "- --save-data - indicates whether to save the training and test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Execute cube-based DCAE:\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "\n",
    "base_path = r'../../datasets/urban'\n",
    "data_file_path = join(base_path, 'urban.npy')\n",
    "ground_truth_path = join(base_path, 'urban_gt.npy')\n",
    "endmembers_path = join(base_path, 'urban_m.npy')\n",
    "train_size = 15500\n",
    "sub_test_size = 47249\n",
    "val_size = 0.1\n",
    "channels_idx = -1\n",
    "batch_size = 256\n",
    "shuffle = True\n",
    "patience = 15\n",
    "model_name = 'unmixing_cube_based_dcae'\n",
    "sample_size = 162\n",
    "neighborhood_size = 5\n",
    "n_classes = 6\n",
    "dest_path = join(base_path, 'results')\n",
    "makedirs(dest_path, exist_ok=True)\n",
    "lr = 0.0005\n",
    "epochs = 15\n",
    "verbose = 2\n",
    "n_runs = 2\n",
    "save_data = False\n",
    "use_mlflow = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\Å‚ukasz\\desktop\\machine-learning\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:125: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  tensor_proto.float_val.extend([np.asscalar(x) for x in proto_values])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 3, 3, 160, 16)     448       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 158, 32)     13856     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 156, 64)     6208      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 154, 128)    24704     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19712)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5046528   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 162)               1134      \n",
      "=================================================================\n",
      "Total params: 5,094,420\n",
      "Trainable params: 5,093,286\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/15\n",
      " - 24s - loss: 27.8451 - spectral_information_divergence_loss: 27.8451 - val_loss: 20.1273 - val_spectral_information_divergence_loss: 20.1273\n",
      "Epoch 2/15\n",
      " - 24s - loss: 17.6595 - spectral_information_divergence_loss: 17.6595 - val_loss: 18.5318 - val_spectral_information_divergence_loss: 18.5318\n",
      "Epoch 3/15\n",
      " - 24s - loss: 16.5297 - spectral_information_divergence_loss: 16.5297 - val_loss: 18.0508 - val_spectral_information_divergence_loss: 18.0508\n",
      "Epoch 4/15\n",
      " - 24s - loss: 16.2116 - spectral_information_divergence_loss: 16.2116 - val_loss: 17.9443 - val_spectral_information_divergence_loss: 17.9443\n",
      "Epoch 5/15\n",
      " - 24s - loss: 16.0754 - spectral_information_divergence_loss: 16.0754 - val_loss: 17.7989 - val_spectral_information_divergence_loss: 17.7989\n",
      "Epoch 6/15\n",
      " - 24s - loss: 16.0060 - spectral_information_divergence_loss: 16.0060 - val_loss: 17.7812 - val_spectral_information_divergence_loss: 17.7812\n",
      "Epoch 7/15\n",
      " - 25s - loss: 15.7264 - spectral_information_divergence_loss: 15.7264 - val_loss: 16.7228 - val_spectral_information_divergence_loss: 16.7228\n",
      "Epoch 8/15\n",
      " - 27s - loss: 15.0309 - spectral_information_divergence_loss: 15.0309 - val_loss: 16.6219 - val_spectral_information_divergence_loss: 16.6219\n",
      "Epoch 9/15\n",
      " - 28s - loss: 14.8788 - spectral_information_divergence_loss: 14.8788 - val_loss: 16.6086 - val_spectral_information_divergence_loss: 16.6086\n",
      "Epoch 10/15\n",
      " - 27s - loss: 14.8575 - spectral_information_divergence_loss: 14.8575 - val_loss: 16.5303 - val_spectral_information_divergence_loss: 16.5303\n",
      "Epoch 11/15\n",
      " - 28s - loss: 14.8257 - spectral_information_divergence_loss: 14.8257 - val_loss: 16.5389 - val_spectral_information_divergence_loss: 16.5389\n",
      "Epoch 12/15\n",
      " - 27s - loss: 14.7862 - spectral_information_divergence_loss: 14.7862 - val_loss: 16.5636 - val_spectral_information_divergence_loss: 16.5636\n",
      "Epoch 13/15\n",
      " - 28s - loss: 14.7321 - spectral_information_divergence_loss: 14.7321 - val_loss: 16.4667 - val_spectral_information_divergence_loss: 16.4667\n",
      "Epoch 14/15\n",
      " - 24s - loss: 14.7810 - spectral_information_divergence_loss: 14.7810 - val_loss: 16.4775 - val_spectral_information_divergence_loss: 16.4775\n",
      "Epoch 15/15\n",
      " - 25s - loss: 14.7330 - spectral_information_divergence_loss: 14.7330 - val_loss: 16.5164 - val_spectral_information_divergence_loss: 16.5164\n",
      "(47249, 6)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 3, 3, 160, 16)     448       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 158, 32)     13856     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 156, 64)     6208      \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 154, 128)    24704     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 19712)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5046528   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 162)               1134      \n",
      "=================================================================\n",
      "Total params: 5,094,420\n",
      "Trainable params: 5,093,286\n",
      "Non-trainable params: 1,134\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/15\n",
      " - 25s - loss: 28.0520 - spectral_information_divergence_loss: 28.0520 - val_loss: 14.6239 - val_spectral_information_divergence_loss: 14.6239\n",
      "Epoch 2/15\n",
      " - 29s - loss: 13.3485 - spectral_information_divergence_loss: 13.3485 - val_loss: 13.2391 - val_spectral_information_divergence_loss: 13.2391\n",
      "Epoch 3/15\n",
      " - 27s - loss: 12.5850 - spectral_information_divergence_loss: 12.5850 - val_loss: 12.8655 - val_spectral_information_divergence_loss: 12.8655\n",
      "Epoch 4/15\n",
      " - 24s - loss: 12.2260 - spectral_information_divergence_loss: 12.2260 - val_loss: 12.6086 - val_spectral_information_divergence_loss: 12.6086\n",
      "Epoch 5/15\n",
      " - 28s - loss: 11.9684 - spectral_information_divergence_loss: 11.9684 - val_loss: 12.4443 - val_spectral_information_divergence_loss: 12.4443\n",
      "Epoch 6/15\n",
      " - 28s - loss: 11.8146 - spectral_information_divergence_loss: 11.8146 - val_loss: 12.3751 - val_spectral_information_divergence_loss: 12.3751\n",
      "Epoch 7/15\n",
      " - 28s - loss: 11.7549 - spectral_information_divergence_loss: 11.7549 - val_loss: 12.3652 - val_spectral_information_divergence_loss: 12.3652\n",
      "Epoch 8/15\n",
      " - 28s - loss: 11.7129 - spectral_information_divergence_loss: 11.7129 - val_loss: 12.3679 - val_spectral_information_divergence_loss: 12.3679\n",
      "Epoch 9/15\n",
      " - 28s - loss: 11.6853 - spectral_information_divergence_loss: 11.6853 - val_loss: 12.3319 - val_spectral_information_divergence_loss: 12.3319\n",
      "Epoch 10/15\n",
      " - 28s - loss: 11.6326 - spectral_information_divergence_loss: 11.6326 - val_loss: 12.3153 - val_spectral_information_divergence_loss: 12.3153\n",
      "Epoch 11/15\n",
      " - 28s - loss: 11.6662 - spectral_information_divergence_loss: 11.6662 - val_loss: 12.2805 - val_spectral_information_divergence_loss: 12.2805\n",
      "Epoch 12/15\n",
      " - 28s - loss: 11.6377 - spectral_information_divergence_loss: 11.6377 - val_loss: 12.2703 - val_spectral_information_divergence_loss: 12.2703\n",
      "Epoch 13/15\n",
      " - 28s - loss: 11.6584 - spectral_information_divergence_loss: 11.6584 - val_loss: 12.3308 - val_spectral_information_divergence_loss: 12.3308\n",
      "Epoch 14/15\n",
      " - 27s - loss: 11.5615 - spectral_information_divergence_loss: 11.5615 - val_loss: 12.2455 - val_spectral_information_divergence_loss: 12.2455\n",
      "Epoch 15/15\n",
      " - 26s - loss: 11.5958 - spectral_information_divergence_loss: 11.5958 - val_loss: 12.2953 - val_spectral_information_divergence_loss: 12.2953\n",
      "(47249, 6)\n",
      "Stats                   mean\n",
      "aRMSE              0.0629979\n",
      "aSAM                0.203302\n",
      "overallRMSE        0.0965472\n",
      "rmsAAD               0.34019\n",
      "perClassSumRMSE      0.55409\n",
      "class0RMSE         0.0892972\n",
      "class1RMSE          0.100922\n",
      "class2RMSE         0.0865959\n",
      "class3RMSE          0.116865\n",
      "class4RMSE          0.091001\n",
      "class5RMSE         0.0694082\n",
      "rRMSE              0.0619477\n",
      "rSID                 2482.64\n",
      "inference_time       32.2219\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from shutil import rmtree\n",
    "from ml_intuition import enums\n",
    "from ml_intuition.data.utils import parse_train_size, subsample_test_set\n",
    "from scripts import prepare_data, artifacts_reporter\n",
    "from scripts.unmixing import train_unmixing, evaluate_unmixing\n",
    "from scripts.unmixing.unmixing_experiments_runner import NEIGHBORHOOD_SIZES, \\\n",
    "    LEARNING_RATES\n",
    "\n",
    "# Iterate through all run in the experiment:\n",
    "for experiment_id in range(n_runs):\n",
    "    experiment_dest_path = os.path.join(\n",
    "        dest_path,\n",
    "        '{}_{}'.format(enums.Experiment.EXPERIMENT, str(experiment_id)))\n",
    "\n",
    "    os.makedirs(experiment_dest_path, exist_ok=True)\n",
    "\n",
    "    # Apply default literature hyperparameters:\n",
    "    if neighborhood_size is None and model_name in NEIGHBORHOOD_SIZES:\n",
    "        neighborhood_size = NEIGHBORHOOD_SIZES[model_name]\n",
    "    if lr is None and model_name in LEARNING_RATES:\n",
    "        lr = LEARNING_RATES[model_name]\n",
    "    # Prepare data for unmixing:\n",
    "    data = prepare_data.main(data_file_path=data_file_path,\n",
    "                             ground_truth_path=ground_truth_path,\n",
    "                             train_size=parse_train_size(train_size),\n",
    "                             val_size=val_size,\n",
    "                             stratified=False,\n",
    "                             background_label=-1,\n",
    "                             channels_idx=channels_idx,\n",
    "                             neighborhood_size=neighborhood_size,\n",
    "                             save_data=save_data,\n",
    "                             seed=experiment_id,\n",
    "                             use_unmixing=True)\n",
    "    # Subsample the test set to constitute a constant size:\n",
    "    if sub_test_size is not None:\n",
    "        subsample_test_set(data[enums.Dataset.TEST], sub_test_size)\n",
    "    # Train the model:\n",
    "    train_unmixing.train(model_name=model_name,\n",
    "                         dest_path=experiment_dest_path,\n",
    "                         data=data,\n",
    "                         sample_size=sample_size,\n",
    "                         neighborhood_size=neighborhood_size,\n",
    "                         n_classes=n_classes,\n",
    "                         lr=lr,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         verbose=verbose,\n",
    "                         shuffle=shuffle,\n",
    "                         patience=patience,\n",
    "                         endmembers_path=endmembers_path,\n",
    "                         seed=experiment_id)\n",
    "    # Evaluate the model:\n",
    "    evaluate_unmixing.evaluate(\n",
    "        model_path=os.path.join(experiment_dest_path, model_name),\n",
    "        data=data,\n",
    "        dest_path=experiment_dest_path,\n",
    "        neighborhood_size=neighborhood_size,\n",
    "        batch_size=batch_size,\n",
    "        endmembers_path=endmembers_path)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "# Save all artifacts and create the report:\n",
    "artifacts_reporter.collect_artifacts_report(\n",
    "    experiments_path=dest_path,\n",
    "    dest_path=dest_path,\n",
    "    use_mlflow=use_mlflow)\n",
    "\n",
    "makedirs(dest_path, exist_ok=True)\n",
    "results = pd.read_csv(join(dest_path, 'report.csv'))\n",
    "print(results.iloc[0])\n",
    "rmtree(dest_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 1, 1, 158, 3)      18        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 1, 1, 79, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 76, 6)       78        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 1, 1, 38, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 34, 12)      372       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 17, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 14, 24)      1176      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 1, 7, 24)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 192)               32448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               28950     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 906       \n",
      "=================================================================\n",
      "Total params: 63,948\n",
      "Trainable params: 63,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/15\n",
      " - 7s - loss: 0.0297 - cnn_rmse: 0.1594 - overall_rms_abundance_angle_distance: 0.5429 - sum_per_class_rmse: 0.9267 - val_loss: 0.0064 - val_cnn_rmse: 0.0801 - val_overall_rms_abundance_angle_distance: 0.2773 - val_sum_per_class_rmse: 0.4746\n",
      "Epoch 2/15\n",
      " - 6s - loss: 0.0052 - cnn_rmse: 0.0717 - overall_rms_abundance_angle_distance: 0.2520 - sum_per_class_rmse: 0.4224 - val_loss: 0.0042 - val_cnn_rmse: 0.0644 - val_overall_rms_abundance_angle_distance: 0.2275 - val_sum_per_class_rmse: 0.3802\n",
      "Epoch 3/15\n",
      " - 5s - loss: 0.0030 - cnn_rmse: 0.0550 - overall_rms_abundance_angle_distance: 0.1937 - sum_per_class_rmse: 0.3242 - val_loss: 0.0026 - val_cnn_rmse: 0.0513 - val_overall_rms_abundance_angle_distance: 0.1761 - val_sum_per_class_rmse: 0.3028\n",
      "Epoch 4/15\n",
      " - 5s - loss: 0.0026 - cnn_rmse: 0.0504 - overall_rms_abundance_angle_distance: 0.1722 - sum_per_class_rmse: 0.2961 - val_loss: 0.0020 - val_cnn_rmse: 0.0451 - val_overall_rms_abundance_angle_distance: 0.1559 - val_sum_per_class_rmse: 0.2650\n",
      "Epoch 5/15\n",
      " - 5s - loss: 0.0021 - cnn_rmse: 0.0455 - overall_rms_abundance_angle_distance: 0.1535 - sum_per_class_rmse: 0.2677 - val_loss: 0.0026 - val_cnn_rmse: 0.0513 - val_overall_rms_abundance_angle_distance: 0.1711 - val_sum_per_class_rmse: 0.3038\n",
      "Epoch 6/15\n",
      " - 5s - loss: 0.0021 - cnn_rmse: 0.0455 - overall_rms_abundance_angle_distance: 0.1525 - sum_per_class_rmse: 0.2671 - val_loss: 0.0020 - val_cnn_rmse: 0.0449 - val_overall_rms_abundance_angle_distance: 0.1468 - val_sum_per_class_rmse: 0.2656\n",
      "Epoch 7/15\n",
      " - 5s - loss: 0.0017 - cnn_rmse: 0.0405 - overall_rms_abundance_angle_distance: 0.1361 - sum_per_class_rmse: 0.2387 - val_loss: 0.0014 - val_cnn_rmse: 0.0370 - val_overall_rms_abundance_angle_distance: 0.1225 - val_sum_per_class_rmse: 0.2167\n",
      "Epoch 8/15\n",
      " - 5s - loss: 0.0014 - cnn_rmse: 0.0367 - overall_rms_abundance_angle_distance: 0.1233 - sum_per_class_rmse: 0.2156 - val_loss: 0.0012 - val_cnn_rmse: 0.0345 - val_overall_rms_abundance_angle_distance: 0.1148 - val_sum_per_class_rmse: 0.2028\n",
      "Epoch 9/15\n",
      " - 5s - loss: 0.0013 - cnn_rmse: 0.0355 - overall_rms_abundance_angle_distance: 0.1200 - sum_per_class_rmse: 0.2082 - val_loss: 0.0011 - val_cnn_rmse: 0.0333 - val_overall_rms_abundance_angle_distance: 0.1140 - val_sum_per_class_rmse: 0.1952\n",
      "Epoch 10/15\n",
      " - 6s - loss: 0.0012 - cnn_rmse: 0.0339 - overall_rms_abundance_angle_distance: 0.1151 - sum_per_class_rmse: 0.1991 - val_loss: 0.0014 - val_cnn_rmse: 0.0371 - val_overall_rms_abundance_angle_distance: 0.1234 - val_sum_per_class_rmse: 0.2166\n",
      "Epoch 11/15\n",
      " - 5s - loss: 0.0014 - cnn_rmse: 0.0376 - overall_rms_abundance_angle_distance: 0.1256 - sum_per_class_rmse: 0.2202 - val_loss: 0.0012 - val_cnn_rmse: 0.0348 - val_overall_rms_abundance_angle_distance: 0.1136 - val_sum_per_class_rmse: 0.2040\n",
      "Epoch 12/15\n",
      " - 5s - loss: 0.0011 - cnn_rmse: 0.0328 - overall_rms_abundance_angle_distance: 0.1111 - sum_per_class_rmse: 0.1929 - val_loss: 0.0011 - val_cnn_rmse: 0.0326 - val_overall_rms_abundance_angle_distance: 0.1091 - val_sum_per_class_rmse: 0.1898\n",
      "Epoch 13/15\n",
      " - 6s - loss: 0.0010 - cnn_rmse: 0.0318 - overall_rms_abundance_angle_distance: 0.1087 - sum_per_class_rmse: 0.1864 - val_loss: 9.5568e-04 - val_cnn_rmse: 0.0309 - val_overall_rms_abundance_angle_distance: 0.1022 - val_sum_per_class_rmse: 0.1810\n",
      "Epoch 14/15\n",
      " - 5s - loss: 0.0011 - cnn_rmse: 0.0333 - overall_rms_abundance_angle_distance: 0.1124 - sum_per_class_rmse: 0.1957 - val_loss: 0.0012 - val_cnn_rmse: 0.0346 - val_overall_rms_abundance_angle_distance: 0.1165 - val_sum_per_class_rmse: 0.2007\n",
      "Epoch 15/15\n",
      " - 5s - loss: 9.3644e-04 - cnn_rmse: 0.0305 - overall_rms_abundance_angle_distance: 0.1036 - sum_per_class_rmse: 0.1788 - val_loss: 9.0551e-04 - val_cnn_rmse: 0.0300 - val_overall_rms_abundance_angle_distance: 0.1011 - val_sum_per_class_rmse: 0.1759\n",
      "(47249, 6)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 1, 1, 158, 3)      18        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 1, 1, 79, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 1, 1, 76, 6)       78        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 1, 1, 38, 6)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 1, 1, 34, 12)      372       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 17, 12)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 1, 1, 14, 24)      1176      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 1, 7, 24)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 168)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 192)               32448     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               28950     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 906       \n",
      "=================================================================\n",
      "Total params: 63,948\n",
      "Trainable params: 63,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13950 samples, validate on 1550 samples\n",
      "Epoch 1/15\n",
      " - 6s - loss: 0.0245 - cnn_rmse: 0.1432 - overall_rms_abundance_angle_distance: 0.4860 - sum_per_class_rmse: 0.8320 - val_loss: 0.0065 - val_cnn_rmse: 0.0805 - val_overall_rms_abundance_angle_distance: 0.2790 - val_sum_per_class_rmse: 0.4781\n",
      "Epoch 2/15\n",
      " - 5s - loss: 0.0056 - cnn_rmse: 0.0744 - overall_rms_abundance_angle_distance: 0.2593 - sum_per_class_rmse: 0.4401 - val_loss: 0.0037 - val_cnn_rmse: 0.0609 - val_overall_rms_abundance_angle_distance: 0.2047 - val_sum_per_class_rmse: 0.3621\n",
      "Epoch 3/15\n",
      " - 5s - loss: 0.0031 - cnn_rmse: 0.0552 - overall_rms_abundance_angle_distance: 0.1868 - sum_per_class_rmse: 0.3270 - val_loss: 0.0023 - val_cnn_rmse: 0.0483 - val_overall_rms_abundance_angle_distance: 0.1631 - val_sum_per_class_rmse: 0.2858\n",
      "Epoch 4/15\n",
      " - 5s - loss: 0.0026 - cnn_rmse: 0.0507 - overall_rms_abundance_angle_distance: 0.1707 - sum_per_class_rmse: 0.2990 - val_loss: 0.0020 - val_cnn_rmse: 0.0447 - val_overall_rms_abundance_angle_distance: 0.1504 - val_sum_per_class_rmse: 0.2638\n",
      "Epoch 5/15\n",
      " - 5s - loss: 0.0021 - cnn_rmse: 0.0458 - overall_rms_abundance_angle_distance: 0.1548 - sum_per_class_rmse: 0.2710 - val_loss: 0.0020 - val_cnn_rmse: 0.0446 - val_overall_rms_abundance_angle_distance: 0.1532 - val_sum_per_class_rmse: 0.2653\n",
      "Epoch 6/15\n",
      " - 5s - loss: 0.0018 - cnn_rmse: 0.0425 - overall_rms_abundance_angle_distance: 0.1446 - sum_per_class_rmse: 0.2511 - val_loss: 0.0018 - val_cnn_rmse: 0.0429 - val_overall_rms_abundance_angle_distance: 0.1450 - val_sum_per_class_rmse: 0.2508\n",
      "Epoch 7/15\n",
      " - 5s - loss: 0.0016 - cnn_rmse: 0.0395 - overall_rms_abundance_angle_distance: 0.1351 - sum_per_class_rmse: 0.2328 - val_loss: 0.0012 - val_cnn_rmse: 0.0349 - val_overall_rms_abundance_angle_distance: 0.1212 - val_sum_per_class_rmse: 0.2065\n",
      "Epoch 8/15\n",
      " - 5s - loss: 0.0013 - cnn_rmse: 0.0358 - overall_rms_abundance_angle_distance: 0.1234 - sum_per_class_rmse: 0.2103 - val_loss: 0.0013 - val_cnn_rmse: 0.0354 - val_overall_rms_abundance_angle_distance: 0.1228 - val_sum_per_class_rmse: 0.2107\n",
      "Epoch 9/15\n",
      " - 5s - loss: 0.0015 - cnn_rmse: 0.0381 - overall_rms_abundance_angle_distance: 0.1301 - sum_per_class_rmse: 0.2240 - val_loss: 0.0017 - val_cnn_rmse: 0.0412 - val_overall_rms_abundance_angle_distance: 0.1311 - val_sum_per_class_rmse: 0.2439\n",
      "Epoch 10/15\n",
      " - 5s - loss: 0.0014 - cnn_rmse: 0.0367 - overall_rms_abundance_angle_distance: 0.1241 - sum_per_class_rmse: 0.2161 - val_loss: 0.0013 - val_cnn_rmse: 0.0366 - val_overall_rms_abundance_angle_distance: 0.1222 - val_sum_per_class_rmse: 0.2138\n",
      "Epoch 11/15\n",
      " - 5s - loss: 0.0011 - cnn_rmse: 0.0334 - overall_rms_abundance_angle_distance: 0.1149 - sum_per_class_rmse: 0.1963 - val_loss: 9.7465e-04 - val_cnn_rmse: 0.0311 - val_overall_rms_abundance_angle_distance: 0.1050 - val_sum_per_class_rmse: 0.1824\n",
      "Epoch 12/15\n",
      " - 5s - loss: 0.0010 - cnn_rmse: 0.0317 - overall_rms_abundance_angle_distance: 0.1094 - sum_per_class_rmse: 0.1862 - val_loss: 9.5730e-04 - val_cnn_rmse: 0.0309 - val_overall_rms_abundance_angle_distance: 0.1050 - val_sum_per_class_rmse: 0.1825\n",
      "Epoch 13/15\n",
      " - 5s - loss: 0.0011 - cnn_rmse: 0.0323 - overall_rms_abundance_angle_distance: 0.1112 - sum_per_class_rmse: 0.1902 - val_loss: 0.0010 - val_cnn_rmse: 0.0323 - val_overall_rms_abundance_angle_distance: 0.1092 - val_sum_per_class_rmse: 0.1887\n",
      "Epoch 14/15\n",
      " - 5s - loss: 9.0748e-04 - cnn_rmse: 0.0300 - overall_rms_abundance_angle_distance: 0.1038 - sum_per_class_rmse: 0.1763 - val_loss: 8.9218e-04 - val_cnn_rmse: 0.0298 - val_overall_rms_abundance_angle_distance: 0.1007 - val_sum_per_class_rmse: 0.1755\n",
      "Epoch 15/15\n",
      " - 5s - loss: 9.6207e-04 - cnn_rmse: 0.0308 - overall_rms_abundance_angle_distance: 0.1061 - sum_per_class_rmse: 0.1811 - val_loss: 0.0010 - val_cnn_rmse: 0.0320 - val_overall_rms_abundance_angle_distance: 0.1130 - val_sum_per_class_rmse: 0.1903\n",
      "(47249, 6)\n",
      "Stats                   mean\n",
      "aRMSE              0.0218583\n",
      "aSAM               0.0666597\n",
      "overallRMSE        0.0303053\n",
      "rmsAAD              0.103071\n",
      "perClassSumRMSE     0.178807\n",
      "class0RMSE         0.0376169\n",
      "class1RMSE         0.0323043\n",
      "class2RMSE         0.0276651\n",
      "class3RMSE         0.0211606\n",
      "class4RMSE         0.0264597\n",
      "class5RMSE         0.0336007\n",
      "inference_time       2.00003\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Execute the pixel-based CNN:\n",
    "endmembers_path = None\n",
    "model_name = 'unmixing_pixel_based_cnn'\n",
    "sample_size = 162\n",
    "lr = 0.01\n",
    "neighborhood_size = None\n",
    "\n",
    "# Iterate through all run in the experiment:\n",
    "for experiment_id in range(n_runs):\n",
    "    experiment_dest_path = os.path.join(\n",
    "        dest_path,\n",
    "        '{}_{}'.format(enums.Experiment.EXPERIMENT, str(experiment_id)))\n",
    "\n",
    "    os.makedirs(experiment_dest_path, exist_ok=True)\n",
    "\n",
    "    # Apply default literature hyperparameters:\n",
    "    if neighborhood_size is None and model_name in NEIGHBORHOOD_SIZES:\n",
    "        neighborhood_size = NEIGHBORHOOD_SIZES[model_name]\n",
    "    if lr is None and model_name in LEARNING_RATES:\n",
    "        lr = LEARNING_RATES[model_name]\n",
    "    # Prepare data for unmixing:\n",
    "    data = prepare_data.main(data_file_path=data_file_path,\n",
    "                             ground_truth_path=ground_truth_path,\n",
    "                             train_size=parse_train_size(train_size),\n",
    "                             val_size=val_size,\n",
    "                             stratified=False,\n",
    "                             background_label=-1,\n",
    "                             channels_idx=channels_idx,\n",
    "                             neighborhood_size=neighborhood_size,\n",
    "                             save_data=save_data,\n",
    "                             seed=experiment_id,\n",
    "                             use_unmixing=True)\n",
    "    # Subsample the test set to constitute a constant size:\n",
    "    if sub_test_size is not None:\n",
    "        subsample_test_set(data[enums.Dataset.TEST], sub_test_size)\n",
    "    # Train the model:\n",
    "    train_unmixing.train(model_name=model_name,\n",
    "                         dest_path=experiment_dest_path,\n",
    "                         data=data,\n",
    "                         sample_size=sample_size,\n",
    "                         neighborhood_size=neighborhood_size,\n",
    "                         n_classes=n_classes,\n",
    "                         lr=lr,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         verbose=verbose,\n",
    "                         shuffle=shuffle,\n",
    "                         patience=patience,\n",
    "                         endmembers_path=endmembers_path,\n",
    "                         seed=experiment_id)\n",
    "    # Evaluate the model:\n",
    "    evaluate_unmixing.evaluate(\n",
    "        model_path=os.path.join(experiment_dest_path, model_name),\n",
    "        data=data,\n",
    "        dest_path=experiment_dest_path,\n",
    "        neighborhood_size=neighborhood_size,\n",
    "        batch_size=batch_size,\n",
    "        endmembers_path=endmembers_path)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "# Save all artifacts and create the report:\n",
    "artifacts_reporter.collect_artifacts_report(\n",
    "    experiments_path=dest_path,\n",
    "    dest_path=dest_path,\n",
    "    use_mlflow=use_mlflow)\n",
    "\n",
    "makedirs(dest_path, exist_ok=True)\n",
    "results = pd.read_csv(join(dest_path, 'report.csv'))\n",
    "print(results.iloc[0])\n",
    "rmtree(dest_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}