{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan on using this implementation, please cite our work:\n",
    "\n",
    "@INPROCEEDINGS{Grabowski2021IGARSS,\n",
    "author={Grabowski, Bartosz and Ziaja, Maciej and Kawulok, Michal\n",
    "and Nalepa, Jakub},\n",
    "booktitle={IGARSS 2021 - 2021 IEEE International Geoscience\n",
    "and Remote Sensing Symposium},\n",
    "title={Towards Robust Cloud Detection in\n",
    "Satellite Images Using U-Nets},\n",
    "year={2021},\n",
    "note={in press}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the cloud detection using U-Net architecture on panchromatic data\n",
    "This document presents the cloud detection on example Landsat 8 panchromatic images using trained U-Net model. The full script can be found in cloud_detection/exp_panchromatic.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import neccessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "from cloud_detection.models import unet\n",
    "from cloud_detection.evaluate_L8CCA import evaluate_model\n",
    "from cloud_detection.losses import (\n",
    "    JaccardIndexLoss,\n",
    "    JaccardIndexMetric,\n",
    "    DiceCoefMetric,\n",
    "    recall,\n",
    "    precision,\n",
    "    specificity,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set the parameters for the experiment.\n",
    "These parameters are the following:\n",
    "\n",
    "\n",
    "- dpath - path to the dataset.\n",
    "- rpath - path to directory where results should be stored.\n",
    "- mpath - path to trained model weights.\n",
    "- vids - tuple of IDs of images which should be used to create visualizations. If contains '*' visualizations will be created for all images in the datasets.\n",
    "- eval_imgs - IDs of images to evaluate.\n",
    "- batch_size - size of generated batches, only one batch is loaded to memory at a time.\n",
    "- thr - threshold for determining whether pixels contain the clouds.\n",
    "- learning_rate - learning rate for training (needed to load the trained model).\n",
    "- bn_momentum - momentum of the batch normalization layer.\n",
    "- bands - band(s) to load (in this case, panchromatic band is loaded).\n",
    "- bands_names - name(s) of the band(s) to load.\n",
    "- resize - whether to resize image to match GT.\n",
    "- normalize - whether to normalize the data.\n",
    "- standardize - whether to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = Path(\"datasets/clouds/Landsat-Cloud-Cover-Assessment-Validation-Data-Partial\")\n",
    "rpath = Path(\"artifacts/panch_cloud_detection_demo/\")\n",
    "mpath = \"examples/panch_cloud_model_weights/best_weights\"\n",
    "vids = [\"*\"]\n",
    "eval_imgs = [\"LC81390292014135LGN00\", \"LC81940222013245LGN00\"]\n",
    "batch_size = 8\n",
    "thr = 0.5\n",
    "learning_rate = 0.01\n",
    "bn_momentum = 0.9\n",
    "bands = (8,)\n",
    "bands_names = (\"panchromatic\",)\n",
    "resize = True\n",
    "normalize = True\n",
    "standardize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the instance of the untrained U-Net model. Next, we load the trained weights into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(input_size=1, bn_momentum=bn_momentum)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "    loss=JaccardIndexLoss(),\n",
    "    metrics=[\n",
    "        keras.metrics.binary_crossentropy,\n",
    "        keras.metrics.binary_accuracy,\n",
    "        JaccardIndexLoss(),\n",
    "        JaccardIndexMetric(),\n",
    "        DiceCoefMetric(),\n",
    "        recall,\n",
    "        precision,\n",
    "        specificity,\n",
    "    ],\n",
    ")\n",
    "model.load_weights(mpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the directory to store the results of the model evaluation. Next, we evaluate the model using example Landsat 8 images. The following files are created for each image:\n",
    "\n",
    "\n",
    "- gt.png - image of the ground-truth cloud mask.\n",
    "- pred.png - image of the model prediction.\n",
    "- masks.png - visualisation of the model prediction. Yellow color denotes True Positives, red color denotes False Positives and purple color stands for False Negatives.\n",
    "- unc.png - uncertainty map, where pixels with uncertain prediction scores are marked in yellow (Note: In the case of the tested model, in most cases almost all of the pixels' prediction scores are very low or very high, which means that the map will almost always not include any yellow pixels.).\n",
    "\n",
    "\n",
    "If the model's prediction Jaccard Index Metric does not exceed 0.6, the following files are also created:\n",
    "\n",
    "\n",
    "- roc.html - ROC curve.\n",
    "- prec_recall.html - precision-recall curve.\n",
    "- activation_hist.html - histogram of the model's activations scores (please note the logarithmic scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Barren-LC81390292014135LGN00\n",
      "Scene prediction took 76.23169779777527 seconds\n",
      "Average inference time: 76.23169779777527 seconds\n",
      "Creating visualisation for LC81390292014135LGN00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgrabowski/Documents/machine-learning/cloud_detection/utils.py:261: UserWarning:\n",
      "\n",
      "artifacts/panch_cloud_detection_demo/eval_vis/LC81390292014135LGN00/gt.png is a low contrast image\n",
      "\n",
      "Lossy conversion from int64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will make insights for LC81390292014135LGN00\n",
      "thr dist variance: 0.0003154964575243529\n",
      "thr dist mean: 0.21808447172536727\n",
      "Optimal thr: 0.99871\n",
      "Processing Urban-LC81940222013245LGN00\n",
      "Scene prediction took 77.1612868309021 seconds\n",
      "Average inference time: 76.69649231433868 seconds\n",
      "Creating visualisation for LC81940222013245LGN00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bgrabowski/Documents/machine-learning/cloud_detection/utils.py:261: UserWarning:\n",
      "\n",
      "artifacts/panch_cloud_detection_demo/eval_vis/LC81940222013245LGN00/gt.png is a low contrast image\n",
      "\n",
      "Lossy conversion from int64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "rpath.mkdir(parents=True, exist_ok=True)\n",
    "metrics_L8CCA, _ = evaluate_model(\n",
    "    model=model,\n",
    "    thr=thr,\n",
    "    dpath=dpath,\n",
    "    rpath=rpath / \"eval_vis\",\n",
    "    vids=vids,\n",
    "    batch_size=batch_size,\n",
    "    bands=bands,\n",
    "    bands_names=bands_names,\n",
    "    img_ids=eval_imgs,\n",
    "    resize=resize,\n",
    "    normalize=normalize,\n",
    "    standardize=standardize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we process the output metrics to obtain the mean metrics for the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L8CCA_binary_crossentropy': 1.3922668, 'L8CCA_binary_accuracy': 0.9127327, 'L8CCA_jaccard_index_loss': 0.2093102, 'L8CCA_jaccard_index_metric': 0.7906898, 'L8CCA_dice_coeff_metric': 0.8691373, 'L8CCA_recall': 0.984382, 'L8CCA_precision': 0.79959816, 'L8CCA_specificity': 0.8915086, 'L8CCA_normalized_mutual_info_score': 0.6823842824300838, 'L8CCA_adjusted_rand_score': 0.7050383172460979}\n"
     ]
    }
   ],
   "source": [
    "mean_metrics_L8CCA = {}\n",
    "for key, value in metrics_L8CCA.items():\n",
    "    mean_metrics_L8CCA[key] = np.mean(list(value.values()))\n",
    "print(mean_metrics_L8CCA)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e38dc96e14b69e70ac9c29573299c49da60d285cf24feefe29a999c69f53110"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('cloud_detection': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
