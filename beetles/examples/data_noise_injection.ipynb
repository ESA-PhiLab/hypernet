{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitdecentconda195be60078e74141843b635847adeecd",
   "display_name": "Python 3.6.10 64-bit ('decent': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Noise injection into data\n",
    "\n",
    "This example presents how the the noise can be injected into any part of the dataset: train, test and validation.\n",
    "There are three types of noise implemented: \n",
    "\n",
    "\n",
    "- Gaussian\n",
    "- Impulsive\n",
    "- Shot\n",
    "\n",
    "\n",
    "\n",
    "There are a few parameters which indicate how a given noise behaves:\n",
    "\n",
    "\n",
    "- *pa* - Fraction of noisy pixels, the number of affected samples is calculated by: floor(n_samples * pa).\n",
    "- *pb* - Fraction of noisy bands. When established the number of samples that undergo noise injection, for each sample the: floor(n_bands * pb) bands are affected.\n",
    "- *bc* - Boolean indicating whether the indexes of affected bands, are constant for each sample. When set to: False, different bands can be augmented with noise for each pixel.\n",
    "- *mean* - Gaussian noise parameter, the mean of the normal distribution.\n",
    "- *std* - Gaussian noise parameter, standard deviation of the normal distribution.\n",
    "- *pw* - Impulsive noise parameter, ratio of whitened pixels for the affected set of samples.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import clize\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "from clize.parameters import multi\n",
    "\n",
    "from scripts import evaluate_model, prepare_data, artifacts_reporter, train_model\n",
    "from ml_intuition.enums import Splits, Experiment\n",
    "from ml_intuition.data.io import load_processed_h5\n",
    "from ml_intuition.data.utils import get_mlflow_artifacts_path, parse_train_size\n",
    "from ml_intuition.data.loggers import log_params_to_mlflow, log_tags_to_mlflow"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Specify path to the `.npy` dataset and ground truth, as well as the output path to store all the artifacts."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_PATH = 'data_noise_injection_results'\n",
    "DATA_FILE_PATH = os.path.join(os.path.dirname(os.getcwd()), 'datasets/pavia/pavia.npy')\n",
    "GT_FILE_PAT = os.path.join(os.path.dirname(os.getcwd()), 'datasets/pavia/pavia_gt.npy')\n",
    "experiment_dest_path = os.path.join(DEST_PATH, 'experiment_0')\n",
    "os.makedirs(experiment_dest_path, exist_ok=True)"
   ]
  },
  {
   "source": [
    "# Prepare the data\n",
    "\n",
    "To fit into the the pipeline, the data has to be preprocessed. It is achieved by the `prepare_data.main` function. It accepts a path to a `.npy` file with the original cube as well as the corresponding ground truth.  In this example, we randomly extract 250 samples from each class (balanced scenario), use 10% of them as validation set, and extract only spectral information of a pixel. The returned object is a dictionary with three keys: `train`, `test` and `val`. Each of them contains an additional dictionary with `data` and `labels` keys, holding corresponding `numpy.ndarray` objects with the data. For more details about the parameters, refer to the documentation of `prepare_data.main` function (located in `scripts/prepare_data`)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.main(data_file_path=DATA_FILE_PATH,\n",
    "                            ground_truth_path=GT_FILE_PAT,\n",
    "                            output_path=None,\n",
    "                            train_size=250,\n",
    "                            val_size=0.1,\n",
    "                            stratified=True,\n",
    "                            background_label=0,\n",
    "                            channels_idx=2,\n",
    "                            neighborhood_size=None,\n",
    "                            save_data=False,\n",
    "                            seed=0)"
   ]
  },
  {
   "source": [
    "# Train the model with nosiy training set\n",
    "\n",
    "The function `trian_model.train` executed the trainig procedure. In order to inject noise into the training set, provide `noise` with a name of the noise type, `noise_sets` with the set you would like to augment, and `noise_params` with the noise parameters. Trained model will be stored under `experiment_dest_path` folder path."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_model.train(model_name='model_2d',\n",
    "                    kernel_size=5,\n",
    "                    n_kernels=200,\n",
    "                    n_layers=1,\n",
    "                    dest_path=experiment_dest_path,\n",
    "                    data=data,\n",
    "                    sample_size=103,\n",
    "                    n_classes=9,\n",
    "                    lr=0.001,\n",
    "                    batch_size=128,\n",
    "                    epochs=200,\n",
    "                    verbose=2,\n",
    "                    shuffle=True,\n",
    "                    patience=15,\n",
    "                    noise=['gaussian'],\n",
    "                    noise_sets=['train'],\n",
    "                    noise_params=\"{\\\"mean\\\": 0, \\\"std\\\": 1, \\\"pa\\\": 0.1, \\\"pb\\\": 1}\")\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 99, 1, 200)        1200      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 1, 200)         200200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               25728     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 828,889\n",
      "Trainable params: 828,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2025 samples, validate on 225 samples\n",
      "Epoch 1/200\n",
      " - 2s - loss: 1.8776 - acc: 0.2390 - val_loss: 1.3069 - val_acc: 0.5244\n",
      "Epoch 2/200\n",
      " - 1s - loss: 1.2942 - acc: 0.5096 - val_loss: 1.0817 - val_acc: 0.6489\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1.0488 - acc: 0.5773 - val_loss: 0.8458 - val_acc: 0.6844\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.8571 - acc: 0.6622 - val_loss: 0.7634 - val_acc: 0.7289\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.7798 - acc: 0.6820 - val_loss: 0.6838 - val_acc: 0.6356\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.6999 - acc: 0.7057 - val_loss: 0.6314 - val_acc: 0.7511\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6292 - acc: 0.7160 - val_loss: 0.6730 - val_acc: 0.6622\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6421 - acc: 0.7279 - val_loss: 0.6066 - val_acc: 0.7511\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.5706 - acc: 0.7462 - val_loss: 0.5435 - val_acc: 0.7689\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.4847 - acc: 0.7921 - val_loss: 0.5501 - val_acc: 0.7956\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.4860 - acc: 0.7951 - val_loss: 0.6575 - val_acc: 0.7111\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.4998 - acc: 0.7881 - val_loss: 0.5474 - val_acc: 0.7422\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.4379 - acc: 0.8143 - val_loss: 0.5357 - val_acc: 0.7378\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.4815 - acc: 0.7896 - val_loss: 0.5660 - val_acc: 0.7644\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.4478 - acc: 0.8089 - val_loss: 0.4934 - val_acc: 0.7733\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.4256 - acc: 0.8089 - val_loss: 0.5716 - val_acc: 0.7422\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.4027 - acc: 0.8267 - val_loss: 0.5396 - val_acc: 0.7822\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.3885 - acc: 0.8306 - val_loss: 0.4510 - val_acc: 0.7778\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.3645 - acc: 0.8425 - val_loss: 0.5031 - val_acc: 0.7822\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.3714 - acc: 0.8375 - val_loss: 0.4682 - val_acc: 0.7956\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.3608 - acc: 0.8469 - val_loss: 0.4599 - val_acc: 0.8444\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.3477 - acc: 0.8523 - val_loss: 0.5151 - val_acc: 0.7733\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.3597 - acc: 0.8494 - val_loss: 0.5178 - val_acc: 0.7867\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.3520 - acc: 0.8528 - val_loss: 0.4771 - val_acc: 0.7911\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.3149 - acc: 0.8647 - val_loss: 0.4903 - val_acc: 0.8222\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.3499 - acc: 0.8390 - val_loss: 0.4844 - val_acc: 0.8267\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.3270 - acc: 0.8578 - val_loss: 0.4659 - val_acc: 0.8222\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.3169 - acc: 0.8667 - val_loss: 0.4782 - val_acc: 0.8267\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.3308 - acc: 0.8598 - val_loss: 0.4581 - val_acc: 0.7867\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.2958 - acc: 0.8770 - val_loss: 0.3715 - val_acc: 0.7956\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.2990 - acc: 0.8741 - val_loss: 0.4265 - val_acc: 0.8222\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.2855 - acc: 0.8770 - val_loss: 0.4218 - val_acc: 0.7867\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.2750 - acc: 0.8849 - val_loss: 0.4143 - val_acc: 0.8133\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.2695 - acc: 0.8844 - val_loss: 0.3566 - val_acc: 0.8667\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.2514 - acc: 0.8963 - val_loss: 0.4516 - val_acc: 0.8044\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.2801 - acc: 0.8879 - val_loss: 0.3582 - val_acc: 0.8267\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.3015 - acc: 0.8770 - val_loss: 0.3937 - val_acc: 0.8044\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.2869 - acc: 0.8721 - val_loss: 0.3548 - val_acc: 0.8222\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.2530 - acc: 0.9027 - val_loss: 0.3383 - val_acc: 0.8444\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.2437 - acc: 0.8993 - val_loss: 0.4022 - val_acc: 0.8400\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.2446 - acc: 0.8914 - val_loss: 0.3633 - val_acc: 0.8311\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.2558 - acc: 0.8953 - val_loss: 0.3692 - val_acc: 0.8311\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.2503 - acc: 0.8899 - val_loss: 0.3771 - val_acc: 0.8711\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.2648 - acc: 0.8943 - val_loss: 0.3894 - val_acc: 0.8444\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.2792 - acc: 0.8894 - val_loss: 0.4229 - val_acc: 0.8178\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.2484 - acc: 0.8973 - val_loss: 0.4699 - val_acc: 0.8667\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.2580 - acc: 0.8983 - val_loss: 0.3728 - val_acc: 0.8444\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.2448 - acc: 0.9032 - val_loss: 0.3569 - val_acc: 0.8800\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.2584 - acc: 0.8998 - val_loss: 0.4528 - val_acc: 0.8533\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.2524 - acc: 0.9037 - val_loss: 0.3271 - val_acc: 0.8444\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.2131 - acc: 0.9081 - val_loss: 0.3332 - val_acc: 0.8400\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.2238 - acc: 0.9141 - val_loss: 0.2969 - val_acc: 0.8667\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.1947 - acc: 0.9170 - val_loss: 0.2855 - val_acc: 0.8622\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.2272 - acc: 0.9081 - val_loss: 0.3061 - val_acc: 0.8533\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.2521 - acc: 0.8869 - val_loss: 0.3415 - val_acc: 0.8667\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.2072 - acc: 0.9195 - val_loss: 0.4266 - val_acc: 0.8356\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.1892 - acc: 0.9254 - val_loss: 0.3007 - val_acc: 0.8800\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.2119 - acc: 0.9146 - val_loss: 0.4083 - val_acc: 0.8444\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.2266 - acc: 0.9091 - val_loss: 0.3553 - val_acc: 0.8756\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.2671 - acc: 0.8968 - val_loss: 0.3355 - val_acc: 0.8533\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.2135 - acc: 0.9131 - val_loss: 0.3507 - val_acc: 0.8578\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.2060 - acc: 0.9116 - val_loss: 0.4814 - val_acc: 0.8222\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.2261 - acc: 0.9052 - val_loss: 0.3173 - val_acc: 0.8711\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.1788 - acc: 0.9323 - val_loss: 0.2993 - val_acc: 0.8578\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.1958 - acc: 0.9195 - val_loss: 0.2669 - val_acc: 0.8889\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.1958 - acc: 0.9210 - val_loss: 0.2668 - val_acc: 0.8844\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.1871 - acc: 0.9264 - val_loss: 0.3078 - val_acc: 0.8800\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.1821 - acc: 0.9269 - val_loss: 0.3319 - val_acc: 0.8578\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.1805 - acc: 0.9264 - val_loss: 0.2229 - val_acc: 0.8933\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.1865 - acc: 0.9254 - val_loss: 0.3069 - val_acc: 0.8578\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.1863 - acc: 0.9294 - val_loss: 0.3000 - val_acc: 0.8800\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.1917 - acc: 0.9131 - val_loss: 0.3670 - val_acc: 0.8578\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.1760 - acc: 0.9299 - val_loss: 0.2915 - val_acc: 0.8889\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.1978 - acc: 0.9141 - val_loss: 0.3211 - val_acc: 0.8756\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.1822 - acc: 0.9200 - val_loss: 0.3128 - val_acc: 0.8489\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.1593 - acc: 0.9368 - val_loss: 0.2444 - val_acc: 0.8844\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.1726 - acc: 0.9348 - val_loss: 0.2547 - val_acc: 0.8978\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.1633 - acc: 0.9333 - val_loss: 0.4057 - val_acc: 0.8667\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.1973 - acc: 0.9249 - val_loss: 0.3414 - val_acc: 0.8800\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.2940 - acc: 0.9047 - val_loss: 0.2978 - val_acc: 0.8800\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.2596 - acc: 0.9032 - val_loss: 0.2688 - val_acc: 0.8756\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.2201 - acc: 0.9131 - val_loss: 0.4018 - val_acc: 0.8444\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.2567 - acc: 0.8978 - val_loss: 0.3062 - val_acc: 0.8711\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.1985 - acc: 0.9235 - val_loss: 0.2886 - val_acc: 0.8756\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Evaluate the model\n",
    "\n",
    "Evaluate the model, calculating all metrics. All arfticats will be stored under provided `experiment_dest_path`. In this step, it is also possible to inject nosie into the `test` set, similarly to the previous function call."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "evaluate_model.evaluate(\n",
    "    model_path=os.path.join(experiment_dest_path, 'model_2d'),\n",
    "    data=data,\n",
    "    dest_path=experiment_dest_path,\n",
    "    n_classes=9,\n",
    "    batch_size=1024,\n",
    "    noise=['gaussian'],\n",
    "    noise_sets=['test'],\n",
    "    noise_params=\"{\\\"mean\\\": 0, \\\"std\\\": 1, \\\"pa\\\": 0.1, \\\"pb\\\": 1}\")\n",
    "tf.keras.backend.clear_session()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}